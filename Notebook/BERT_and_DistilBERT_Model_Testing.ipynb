{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_AMvH3ljzKn"
      },
      "outputs": [],
      "source": [
        "# Transformers installation\n",
        "! pip install transformers datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load SQuAD dataset\n",
        "from datasets import load_dataset\n",
        "\n",
        "# split into train and test set with the train_test_split method\n",
        "squad = load_dataset(\"squad\", split=\"train[:5000]\")\n",
        "squad = squad.train_test_split(test_size=0.2)"
      ],
      "metadata": {
        "id": "_xlMz3NukmHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load tokenizer to process the question and context fields\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
      ],
      "metadata": {
        "id": "c3M3l5BilMFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"context\"],\n",
        "        max_length=384,\n",
        "        truncation=\"only_second\",\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "    answers = examples[\"answers\"]\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offset in enumerate(offset_mapping):\n",
        "        answer = answers[i]\n",
        "        start_char = answer[\"answer_start\"][0]\n",
        "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "        # Find the start and end of the context\n",
        "        idx = 0\n",
        "        # print(i, sequence_ids)\n",
        "        while sequence_ids[idx] != 1:\n",
        "            idx += 1\n",
        "        context_start = idx\n",
        "        while sequence_ids[idx] == 1:\n",
        "            idx += 1\n",
        "        context_end = idx - 1\n",
        "\n",
        "        # If the answer is not fully inside the context, label it (0, 0)\n",
        "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            # Otherwise it's the start and end token positions\n",
        "            idx = context_start\n",
        "            while idx <= context_end and offset[idx][0] <= start_char:\n",
        "                idx += 1\n",
        "            start_positions.append(idx - 1)\n",
        "\n",
        "            idx = context_end\n",
        "            while idx >= context_start and offset[idx][1] >= end_char:\n",
        "                idx -= 1\n",
        "            end_positions.append(idx + 1)\n",
        "\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "F9fY2ilklr8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To apply the preprocessing function over the entire dataset, use the map function\n",
        "tokenized_squad = squad.map(preprocess_function, batched=True, remove_columns=squad[\"train\"].column_names)"
      ],
      "metadata": {
        "id": "mn6AuzJnl0gF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for creating a batch of examples using DefaultDataCollator\n",
        "from transformers import DefaultDataCollator\n",
        "\n",
        "data_collator = DefaultDataCollator(return_tensors=\"tf\")"
      ],
      "metadata": {
        "id": "W5brt4Mnl909"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting up an optimizer function, learning rate schedule, and some training hyperparameters\n",
        "from transformers import create_optimizer\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 3\n",
        "total_train_steps = (len(tokenized_squad[\"train\"]) // batch_size) * num_epochs\n",
        "optimizer, schedule = create_optimizer(\n",
        "    init_lr=5e-5,\n",
        "    num_warmup_steps=0,\n",
        "    num_train_steps=total_train_steps,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "DIk41y8nmOuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pick the model which will be evaluated for CO2 emissions\n",
        "from transformers import TFAutoModelForQuestionAnswering\n",
        "\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "# model_name = 'bert-base-uncased'\n",
        "model = TFAutoModelForQuestionAnswering.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "id": "IeuDJ4_5mbAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert datasets to the tf.data.Dataset format with prepare_tf_dataset()\n",
        "tf_train_set = model.prepare_tf_dataset(\n",
        "    tokenized_squad[\"train\"],\n",
        "    shuffle=True,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "tf_validation_set = model.prepare_tf_dataset(\n",
        "    tokenized_squad[\"test\"],\n",
        "    shuffle=False,\n",
        "    batch_size=16,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "# configure model for training with the compile method\n",
        "import tensorflow as tf\n",
        "\n",
        "model.compile(optimizer=optimizer)"
      ],
      "metadata": {
        "id": "gKxosketmwPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "device_name\n",
        "\n",
        "# train model\n",
        "with tf.device('/device:GPU:0'):\n",
        "    model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=3)"
      ],
      "metadata": {
        "id": "IyVErAeEm98r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use codecarbon package to measure the carbon emissions of the model\n",
        "! pip install codecarbon\n",
        "from codecarbon import EmissionsTracker\n",
        "\n",
        "with EmissionsTracker(project_name=\"bert-base-uncased\") as tracker:\n",
        "    with tf.device('/device:GPU:0'):\n",
        "        history = model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=2)\n",
        "\n",
        "print(tracker.final_emissions)"
      ],
      "metadata": {
        "id": "HtwhE4pfnodi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# total CO2 emissions and validation loss\n",
        "print(f\"Total emission of kilograms of CO2 is: {tracker.final_emissions}\")\n",
        "print(f\"Final error of the model is: {history.history['val_loss'][-1]}\")"
      ],
      "metadata": {
        "id": "Z4tS3A-hq4K9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "import os\n",
        "import openai\n",
        "openai.api_key  = os.getenv('enter your API key here')\n",
        "\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "!pip install openai\n",
        "\n",
        "def answer_question(prompt, question):\n",
        "    inputs = tokenizer(prompt, question, add_special_tokens=True, return_tensors=\"tf\")\n",
        "    input_ids = inputs[\"input_ids\"].numpy()[0]\n",
        "    attention_mask = inputs[\"attention_mask\"].numpy()[0]\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    answer_start = tf.argmax(outputs.start_logits, axis=1).numpy()[0]\n",
        "    answer_end = tf.argmax(outputs.end_logits, axis=1).numpy()[0]\n",
        "\n",
        "    answer = tokenizer.decode(input_ids[answer_start:answer_end+1], skip_special_tokens=True)\n",
        "    return answer"
      ],
      "metadata": {
        "id": "Gq5TSjnrnLKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_cosine_similarity(sentence1: str, sentence2: str) -> float:\n",
        "    \"\"\"\n",
        "    Calculate the cosine similarity between two sentences.\n",
        "\n",
        "    Args:\n",
        "        sentence1 (str): The first sentence.\n",
        "        sentence2 (str): The second sentence.\n",
        "\n",
        "    Returns:\n",
        "        float: The cosine similarity between the two sentences, represented as a float value between 0 and 1.\n",
        "    \"\"\"\n",
        "    # Tokenize the sentences into words\n",
        "    words1 = sentence1.lower().split()\n",
        "    words2 = sentence2.lower().split()\n",
        "\n",
        "    # Create a set of unique words from both sentences\n",
        "    unique_words = set(words1 + words2)\n",
        "\n",
        "    # Create a frequency vector for each sentence\n",
        "    freq_vector1 = np.array([words1.count(word) for word in unique_words])\n",
        "    freq_vector2 = np.array([words2.count(word) for word in unique_words])\n",
        "\n",
        "    # Calculate the cosine similarity between the frequency vectors\n",
        "    similarity = 1 - cosine(freq_vector1, freq_vector2)\n",
        "\n",
        "    return similarity\n",
        "\n",
        "def levenshtein_distance(s1: str, s2: str) -> float:\n",
        "    \"\"\"\n",
        "    Compute the Levenshtein distance between two strings.\n",
        "\n",
        "    Args:\n",
        "        s1 (str): The first string.\n",
        "        s2 (str): The second string.\n",
        "\n",
        "    Returns:\n",
        "        float: The Levenshtein distance between the two strings.\n",
        "    \"\"\"\n",
        "    m = len(s1)\n",
        "    n = len(s2)\n",
        "\n",
        "    # Create a matrix to store the distances between substrings of s1 and s2\n",
        "    d = [[0] * (n + 1) for _ in range(m + 1)]\n",
        "\n",
        "    # Initialize the first row and column of the matrix\n",
        "    for i in range(m + 1):\n",
        "        d[i][0] = i\n",
        "    for j in range(n + 1):\n",
        "        d[0][j] = j\n",
        "\n",
        "    # Compute the distances between all substrings of s1 and s2\n",
        "    for j in range(1, n + 1):\n",
        "        for i in range(1, m + 1):\n",
        "            if s1[i - 1] == s2[j - 1]:\n",
        "                d[i][j] = d[i - 1][j - 1]\n",
        "            else:\n",
        "                d[i][j] = min(d[i - 1][j], d[i][j - 1], d[i - 1][j - 1]) + 1\n",
        "\n",
        "    # Return the Levenshtein distance between the two strings\n",
        "    return d[m][n]*(-1)"
      ],
      "metadata": {
        "id": "OdhOBNVInYtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_index_integers=np.random.randint(len(squad[\"train\"]), size=100)\n",
        "\n",
        "!pip install google-generativeai openai sentence-transformers\n",
        "!pip install sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "import google.generativeai as palm"
      ],
      "metadata": {
        "id": "qZmxJdo9oM77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the models using cosine similarity and STS scores and testing on samples from the SQuAD dataset\n",
        "\n",
        "scores_1 = []\n",
        "scores_2 = []\n",
        "scores_3 = []\n",
        "scores_4 = []\n",
        "def openai_text_embedding(prompt: str, key: str) -> str:\n",
        "    # API Key\n",
        "    openai.api_key = key\n",
        "\n",
        "    return openai.Embedding.create(\n",
        "        input=prompt, model=\"text-embedding-ada-002\"\n",
        "    )[\"data\"][0][\"embedding\"]\n",
        "\n",
        "def palm_text_embedding(prompt: str, key: str) -> str:\n",
        "    # API Key\n",
        "    palm.configure(api_key=key)\n",
        "    model = \"models/embedding-gecko-001\"\n",
        "\n",
        "    return palm.generate_embeddings(model=model, text=prompt)['embedding']\n",
        "\n",
        "\n",
        "def calculate_cosine_similarity(sentence1: str, sentence2: str) -> float:\n",
        "    \"\"\"\n",
        "    Calculate the cosine similarity between two sentences.\n",
        "\n",
        "    Args:\n",
        "        sentence1 (str): The first sentence.\n",
        "        sentence2 (str): The second sentence.\n",
        "\n",
        "    Returns:\n",
        "        float: The cosine similarity between the two sentences, represented as a float value between 0 and 1.\n",
        "    \"\"\"\n",
        "    # Tokenize the sentences into words\n",
        "    words1 = sentence1.lower().split()\n",
        "    words2 = sentence2.lower().split()\n",
        "\n",
        "    # Create a set of unique words from both sentences\n",
        "    unique_words = set(words1 + words2)\n",
        "\n",
        "    # Create a frequency vector for each sentence\n",
        "    freq_vector1 = np.array([words1.count(word) for word in unique_words])\n",
        "    freq_vector2 = np.array([words2.count(word) for word in unique_words])\n",
        "\n",
        "    # Calculate the cosine similarity between the frequency vectors\n",
        "    similarity = 1 - cosine(freq_vector1, freq_vector2)\n",
        "\n",
        "    return similarity\n",
        "\n",
        "def calculate_sts_score(sentence1: str, sentence2: str) -> float:\n",
        "    model = SentenceTransformer(\n",
        "        \"paraphrase-MiniLM-L6-v2\"\n",
        "    )\n",
        "\n",
        "    # Compute sentence embeddings\n",
        "    embedding1 = model.encode([sentence1])[0]  # Flatten the embedding array\n",
        "    embedding2 = model.encode([sentence2])[0]  # Flatten the embedding array\n",
        "\n",
        "    # Calculate cosine similarity between the embeddings\n",
        "    similarity_score = 1 - cosine(embedding1, embedding2)\n",
        "\n",
        "    return similarity_score\n",
        "\n",
        "\n",
        "def calculate_sts_openai_score(sentence1: str, sentence2: str, key: str) -> float:\n",
        "    # Compute sentence embeddings\n",
        "    embedding1 = openai_text_embedding(sentence1, key) # Flatten the embedding array\n",
        "    embedding2 = openai_text_embedding(sentence2, key)  # Flatten the embedding array\n",
        "\n",
        "    # Convert to array\n",
        "    embedding1 = np.asarray(embedding1)\n",
        "    embedding2 = np.asarray(embedding2)\n",
        "\n",
        "    # Calculate cosine similarity between the embeddings\n",
        "    similarity_score = 1 - cosine(embedding1, embedding2)\n",
        "\n",
        "    return similarity_score\n",
        "\n",
        "def calculate_sts_palm_score(sentence1: str, sentence2: str, key: str) -> float:\n",
        "    # Compute sentence embeddings\n",
        "    embedding1 = palm_text_embedding(sentence1, key) # Flatten the embedding array\n",
        "    embedding2 = palm_text_embedding(sentence2, key)  # Flatten the embedding array\n",
        "\n",
        "    # Convert to array\n",
        "    embedding1 = np.asarray(embedding1)\n",
        "    embedding2 = np.asarray(embedding2)\n",
        "\n",
        "    # Calculate cosine similarity between the embeddings\n",
        "    similarity_score = 1 - cosine(embedding1, embedding2)\n",
        "\n",
        "    return similarity_score\n",
        "\n",
        "random_index_integers=np.random.randint(len(squad[\"train\"]), size=100)\n",
        "# np.random.randint(0, len(squad[\"train\"]), 100)\n",
        "random_index_integers\n",
        "for i in random_index_integers:\n",
        "    current_sample = squad['train'][int(i)]\n",
        "\n",
        "    # Collect context + question\n",
        "    prompt = current_sample['context']\n",
        "    question = current_sample['question']\n",
        "    if len(prompt)<2:\n",
        "      prediction = \"N/A\"\n",
        "    if len(question)<2:\n",
        "      prediction = \"N/A\"\n",
        "    # prediction\n",
        "    prediction = answer_question(prompt, question)\n",
        "    if len(prediction)<2:\n",
        "      prediction = \"no output found\"\n",
        "\n",
        "    # save ground truth\n",
        "    ground_truth = current_sample['answers']['text'][0]\n",
        "\n",
        "    # compare answers\n",
        "    score1 = calculate_cosine_similarity(prediction, ground_truth)\n",
        "    score2 = calculate_sts_score(prediction, ground_truth)\n",
        "    score3 = calculate_sts_openai_score(prediction, ground_truth, \"enter your API key here\")\n",
        "    score4 = calculate_sts_palm_score(prediction, ground_truth, \"enter your API key here\")\n",
        "\n",
        "    # collect scores\n",
        "    scores_1.append(score1)\n",
        "    scores_2.append(score2)\n",
        "    scores_3.append(score3)\n",
        "    scores_4.append(score4)"
      ],
      "metadata": {
        "id": "lsM9ITbjorDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#print avg and stdev of each similarity score for the SQuAD dataset\n",
        "\n",
        "print(np.mean(scores_1), np.std(scores_1))\n",
        "print(np.mean(scores_2), np.std(scores_2))\n",
        "print(np.mean(scores_3), np.std(scores_3))\n",
        "print(np.mean(scores_4), np.std(scores_4))"
      ],
      "metadata": {
        "id": "WTUnVZJvpAxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "# load AdversarialQA dataset\n",
        "dataset = load_dataset(\"adversarial_qa\", \"adversarialQA\")"
      ],
      "metadata": {
        "id": "ckCOPXnguOTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "contexts = []\n",
        "questions = []\n",
        "answers = []\n",
        "for i in tqdm(range(20)):\n",
        "    curr_sample = dataset['validation'][i]\n",
        "    contexts.append(curr_sample['context'])\n",
        "    questions.append(curr_sample['question'])\n",
        "    answers.append(curr_sample['answers']['text'][0])\n",
        "\n",
        "df1 = pd.DataFrame()\n",
        "df1['context'] = contexts\n",
        "df1['question'] = questions\n",
        "df1['answer'] = answers"
      ],
      "metadata": {
        "id": "Mv1Nz49ouhpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the models using cosine similarity and STS scores and testing on samples from the AdversarialQA dataset\n",
        "\n",
        "scores_1 = []\n",
        "scores_2 = []\n",
        "scores_3 = []\n",
        "scores_4 = []\n",
        "def openai_text_embedding(prompt: str, key: str) -> str:\n",
        "    # API Key\n",
        "    openai.api_key = key\n",
        "\n",
        "    return openai.Embedding.create(\n",
        "        input=prompt, model=\"text-embedding-ada-002\"\n",
        "    )[\"data\"][0][\"embedding\"]\n",
        "\n",
        "def palm_text_embedding(prompt: str, key: str) -> str:\n",
        "    # API Key\n",
        "    palm.configure(api_key=key)\n",
        "    model = \"models/embedding-gecko-001\"\n",
        "\n",
        "    return palm.generate_embeddings(model=model, text=prompt)['embedding']\n",
        "\n",
        "\n",
        "def calculate_cosine_similarity(sentence1: str, sentence2: str) -> float:\n",
        "    \"\"\"\n",
        "    Calculate the cosine similarity between two sentences.\n",
        "\n",
        "    Args:\n",
        "        sentence1 (str): The first sentence.\n",
        "        sentence2 (str): The second sentence.\n",
        "\n",
        "    Returns:\n",
        "        float: The cosine similarity between the two sentences, represented as a float value between 0 and 1.\n",
        "    \"\"\"\n",
        "    # Tokenize the sentences into words\n",
        "    words1 = sentence1.lower().split()\n",
        "    words2 = sentence2.lower().split()\n",
        "\n",
        "    # Create a set of unique words from both sentences\n",
        "    unique_words = set(words1 + words2)\n",
        "\n",
        "    # Create a frequency vector for each sentence\n",
        "    freq_vector1 = np.array([words1.count(word) for word in unique_words])\n",
        "    freq_vector2 = np.array([words2.count(word) for word in unique_words])\n",
        "\n",
        "    # Calculate the cosine similarity between the frequency vectors\n",
        "    similarity = 1 - cosine(freq_vector1, freq_vector2)\n",
        "\n",
        "    return similarity\n",
        "\n",
        "def calculate_sts_score(sentence1: str, sentence2: str) -> float:\n",
        "    model = SentenceTransformer(\n",
        "        \"paraphrase-MiniLM-L6-v2\"\n",
        "    )\n",
        "\n",
        "    # Compute sentence embeddings\n",
        "    embedding1 = model.encode([sentence1])[0]  # Flatten the embedding array\n",
        "    embedding2 = model.encode([sentence2])[0]  # Flatten the embedding array\n",
        "\n",
        "    # Calculate cosine similarity between the embeddings\n",
        "    similarity_score = 1 - cosine(embedding1, embedding2)\n",
        "\n",
        "    return similarity_score\n",
        "\n",
        "\n",
        "def calculate_sts_openai_score(sentence1: str, sentence2: str, key: str) -> float:\n",
        "    # Compute sentence embeddings\n",
        "    embedding1 = openai_text_embedding(sentence1, key) # Flatten the embedding array\n",
        "    embedding2 = openai_text_embedding(sentence2, key)  # Flatten the embedding array\n",
        "\n",
        "    # Convert to array\n",
        "    embedding1 = np.asarray(embedding1)\n",
        "    embedding2 = np.asarray(embedding2)\n",
        "\n",
        "    # Calculate cosine similarity between the embeddings\n",
        "    similarity_score = 1 - cosine(embedding1, embedding2)\n",
        "\n",
        "    return similarity_score\n",
        "\n",
        "def calculate_sts_palm_score(sentence1: str, sentence2: str, key: str) -> float:\n",
        "    # Compute sentence embeddings\n",
        "    embedding1 = palm_text_embedding(sentence1, key) # Flatten the embedding array\n",
        "    embedding2 = palm_text_embedding(sentence2, key)  # Flatten the embedding array\n",
        "\n",
        "    # Convert to array\n",
        "    embedding1 = np.asarray(embedding1)\n",
        "    embedding2 = np.asarray(embedding2)\n",
        "\n",
        "    # Calculate cosine similarity between the embeddings\n",
        "    similarity_score = 1 - cosine(embedding1, embedding2)\n",
        "\n",
        "    return similarity_score\n",
        "\n",
        "random_index_integers=np.random.randint(len(dataset[\"train\"]), size=100)\n",
        "# np.random.randint(0, len(df1[\"train\"]), 100)\n",
        "random_index_integers\n",
        "for i in random_index_integers:\n",
        "    current_sample = dataset['train'][int(i)]\n",
        "\n",
        "    # Collect context + question\n",
        "    prompt = current_sample['context']\n",
        "    question = current_sample['question']\n",
        "    if len(prompt)<2:\n",
        "      prediction = \"N/A\"\n",
        "    if len(question)<2:\n",
        "      prediction = \"N/A\"\n",
        "    # prediction\n",
        "    prediction = answer_question(prompt, question)\n",
        "    if len(prediction)<2:\n",
        "      prediction = \"no output found\"\n",
        "\n",
        "    # save ground truth\n",
        "    ground_truth = current_sample['answers']['text'][0]\n",
        "\n",
        "    # compare answers\n",
        "    score1 = calculate_cosine_similarity(prediction, ground_truth)\n",
        "    score2 = calculate_sts_score(prediction, ground_truth)\n",
        "    score3 = calculate_sts_openai_score(prediction, ground_truth, \"enter your API key here\")\n",
        "    score4 = calculate_sts_palm_score(prediction, ground_truth, \"enter your API key here\")\n",
        "\n",
        "    # collect scores\n",
        "    scores_1.append(score1)\n",
        "    scores_2.append(score2)\n",
        "    scores_3.append(score3)\n",
        "    scores_4.append(score4)"
      ],
      "metadata": {
        "id": "_JFxn1U_uSLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print avg and stdev of each similarity score for the AdversarialQA dataset\n",
        "\n",
        "print(np.mean(scores_1), np.std(scores_1))\n",
        "print(np.mean(scores_2), np.std(scores_2))\n",
        "print(np.mean(scores_3), np.std(scores_3))\n",
        "print(np.mean(scores_4), np.std(scores_4))"
      ],
      "metadata": {
        "id": "oVAPz4MqufoA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}